# ğŸ¬ Agentic RAG Anime Recommender System

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://appudtzei3tyyttd6xjhwur.streamlit.app/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GitHub Star](https://img.shields.io/github/stars/Ratnesh-181998/Agentic-RAG-Anime-Recommender-System?style=social)](https://github.com/Ratnesh-181998/Agentic-RAG-Anime-Recommender-System)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat&logo=linkedin)](https://www.linkedin.com/in/ratneshkumar1998/)

![Banner](assets/banner.png)

> **A production-grade, Agentic Retrieval-Augmented Generation (RAG) system for semantic anime discovery. Powered by Groq, LangChain, and ChromaDB.**

---

## ğŸ“ Table of Contents
- [ğŸŒŸ Overview & Core Mission](#-overview--core-mission)
- [ğŸ·ï¸ Tech Stack & Keywords](#ï¸-tech-stack--keywords)
- [ğŸ—ï¸ System Architecture](#ï¸-system-architecture)
- [ï¿½ Project Structure](#-project-structure)
- [ï¿½ğŸ“± Interactive UI Showcase](#-interactive-ui-showcase)
- [ğŸš€ LLMOps & Deployment Playbook](#-llmops--deployment-playbook)
- [ï¿½ Performance Benchmarks](#-performance-benchmarks)
- [ï¿½ğŸ› ï¸ Developer Setup](#ï¸-developer-setup)
- [ï¿½ï¸ Future Roadmap](#ï¸-future-roadmap)
- [ğŸ“ Contact & Networking](#-contact--networking)

---

## ğŸŒŸ Overview & Core Mission

### ğŸ¯ The Challenge
In a world with thousands of anime titles, generic category-based recommendation systems fail to capture the **nuance of human emotion, atmosphere, and complex plot themes**. 

### âœ… The Solution
The **Agentic RAG Anime Recommender** is an advanced AI platform that implements **Semantic Search** and **Personalized Discovery** using a **Content-Based Filtering** approach enhanced by Large Language Models (**LLMs**). It understands the "vibe" of a query and provides a reasoning layer that explains the logic behind every suggestion.

> **Pro Tip**: Use queries like *"Find me an anime that feels like a lonely evening in a cyberpunk city"* to see the power of semantic retrieval.

---

## ğŸ·ï¸ Tech Stack & Keywords

### ğŸ§  Expertise Matrix

| Category | Keywords & Skills |
| :--- | :--- |
| **ğŸ¤– AI/ML** | **LLM (Llama 3.1)**, **RAG**, **Agentic AI**, **Semantic Search**, **Vector Embeddings (MiniLM)**, **Contextual Retrieval** |
| **ğŸ› ï¸ Tech Stack** | **Groq LPU Acceleration**, **LangChain**, **ChromaDB (HNSW Index)**, **HuggingFace Transformers**, **Python**, **Streamlit Premium UI** |
| **â˜ï¸ LLMOps / AIOps** | **Docker Containerization**, **Kubernetes (K8s)**, **GKE**, **CI/CD Pipelines (GitHub Actions)**, **Grafana Observability** |
| **ğŸ¯ Domain** | **Recommender Systems**, **Content-Based Filtering**, **Cold Start Mitigation**, **Persona-Based Discovery** |

---

## ğŸ—ï¸ System Architecture

### ğŸ“Š Tactical Data Flow
```mermaid
graph LR
    subgraph Data Layer
    CSV[(Anime Metadata)] --> EMD[HuggingFace Embeddings]
    EMD --> VDB[(ChromaDB)]
    end

    subgraph Logic Layer
    User([User Query]) --> VDB
    VDB -- Top-K Matches --> RE[Groq Reasoning Engine]
    RE -- Agentic Insight --> UI
    end

    subgraph Presentation Layer
    UI[[Streamlit Premium UI]]
    end
```

### ğŸ–¼ï¸ Architecture & Workflow Visuals

<details>
<summary><b>ğŸ“ View High-Level & Low-Level Design (HLD/LLD)</b></summary>

![HLD & LLD](assets/hld_lld.png)
</details>

<details>
<summary><b>ğŸ”„ View Agentic Workflow Detail</b></summary>

![Workflow](assets/workflow.png)
</details>

### ğŸ” Process Deep Dive
1.  **Ingestion Phase**: CSV metadata is normalized, tokenized, and transformed into 384-dimensional dense vectors using `all-MiniLM-L6-v2`.
2.  **Indexing Phase**: **ChromaDB** maintains a persistent HNSW index for sub-10ms nearest neighbor search.
3.  **Inference Phase**: **Groq (LPU)** processes retrieved context and user intent to generate a reasoned analysis.
4.  **Presentation Phase**: Real-time rendering of results with interactive UX feedback loops and CSS transitions.

---

## ï¿½ Project Structure

```text
â”œâ”€â”€ Code/                   # Application Pipeline, Logic & UI Components
â”œâ”€â”€ Dataset Used/           # Raw Metadata Source (CSV)
â”œâ”€â”€ Project Doc/            # Detailed Documentation & Checklists
â”œâ”€â”€ assets/                 # Brand Assets, Architecture Diagrams & UI Screenshots
â”œâ”€â”€ README.md               # Hero Documentation & Professional Overview
â”œâ”€â”€ LICENSE                 # MIT Open Source License
â”œâ”€â”€ requirements.txt        # Python Dependencies
â”œâ”€â”€ Dockerfile              # Containerization Script
â”œâ”€â”€ setup.py                # Package Configuration
â”œâ”€â”€ chroma_db/               # Persistent Vector Database (ChromaDB)
â””â”€â”€ llmops-k8s.yaml         # Kubernetes Orchestration Blueprint
```

---

## ğŸ“± Interactive UI Showcase & Tab Guide

The application features a premium, multi-tab interface designed for both casual discovery and technical deep-dives.

### ï¿½ Tab 1: Demo Project (Core Experience)
*   **Purpose**: The central interaction point for users to get recommendations.
*   **Features**:
    *   **âš¡ Quick Try Grid**: 16 categorized buttons (e.g., *Cyberpunk*, *Dark Fantasy*) for one-click exploration.
    *   **ğŸ” Semantic Search Bar**: A deep-learning powered input where users can describe their "ideal vibe" in natural language.
    *   **ğŸ’¾ Query History**: Persistent track of previous searches with the ability to copy or download results as `.txt` files.
    *   **ğŸ§  AI Reasoning Engine**: Not just a list, but a detailed analysis of *why* each anime was recommended.

### ğŸ“– Tab 2: About Project (The Vision)
*   **Purpose**: Outlines the problem statement and the architectural "Why".
*   **Features**:
    *   **ğŸ’¡ Problem vs. Solution**: A clear breakdown of the challenges in traditional recommendation systems and how Agentic RAG solves them.
    *   **ğŸ¯ Project Goals**: Highlighting scalability, sub-second latency, and semantic accuracy.

### ğŸ”§ Tab 3: Tech Stack (Technical Pedigree)
*   **Purpose**: A live monitor and description of the underlying technology.
*   **Features**:
    *   **ğŸ“¡ Live Pulse**: Real-time metrics for LLM latency (Groq) and Vector DB status.
    *   **ğŸ› ï¸ Component Breakdown**: Detailed logic behind choosing **ChromaDB**, **LangChain**, and **HuggingFace**.
    *   **ğŸ“Š Tech Comparison**: A tabular comparison of this stack vs. traditional alternatives.

### ğŸ—ï¸ Tab 4: Architecture (Systems Design)
*   **Purpose**: For engineers to understand the data flow and orchestration.
*   **Features**:
    *   **ğŸ“ HLD/LLD Diagrams**: Visual maps of the multi-phase pipeline (Ingestion â†’ Retrieval â†’ Reasoning).
    *   **ğŸ”„ Workflow Detail**: Step-by-step logic of how a query is transformed and reasoned upon.

### ğŸ“‹ Tab 5: System Logs (Observability)
*   **Purpose**: Full transparency into the application's backend health.
*   **Features**:
    *   **ğŸ“œ Live Event Stream**: Real-time logging of API calls, database queries, and error handling.
    *   **ğŸ›ï¸ Filter & Search**: Ability to filter logs by `INFO`, `SUCCESS`, `WARNING`, or `ERROR`.
    *   **ğŸ“Š Log Metrics**: Statistical breakdown of system success rates and event counts.

---

## ğŸš€ LLMOps & Deployment Playbook

### ğŸ—ï¸ CI/CD Pipeline
Integrated with **GitHub Actions** for automated:
- Code Quality Linting (`Pylint`, `Flake8`)
- Container Image Builds
- Registry Push (Artifact Registry / ECR)

### â˜ï¸ Cloud Strategy

| Provider | Method | Command Snippet |
| :--- | :--- | :--- |
| **GCP** | GKE (Kubernetes) | `kubectl apply -f llmops-k8s.yaml` |
| **AWS** | EKS (Fargate) | `eksctl create cluster --name anime-rag` |
| **Cloud** | Streamlit Cloud | Auto-deploy from `main` branch |

---

## ğŸ› ï¸ Production Deployment (GCP + K8s)

For professional infrastructure, we utilize **Google Cloud Platform (GCP)** with **Ubuntu 24.04 LTS** and **Minikube** for local Kubernetes orchestration.

### 1. VM Provisioning (GCP)
- **Machine Type**: `E2-Standard-4` (4 vCPU, 16 GB RAM)
- **Boot Disk**: 256 GB SSD (Ubuntu 24.04 LTS)
- **Networking**: Allow Port `8501` (Streamlit Default)

### 2. Kubernetes Orchestration
```bash
# Point Docker to Minikube context
eval $(minikube docker-env)

# Build & Deploy
docker build -t llmops-app:latest .
kubectl apply -f llmops-k8s.yaml

# Expose Service
kubectl port-forward svc/llmops-service 8501:80 --address 0.0.0.0
```

---

## ğŸ“Š Enterprise Monitoring (Grafana)

We implement **Full-Stack Observability** using **Grafana Cloud** via Helm charts to monitor cluster health and application metrics.

### ğŸ” Monitoring Steps:
1. **Namespace isolation**: `kubectl create ns monitoring`
2. **HELM Integration**:
   ```bash
   helm repo add grafana https://grafana.github.io/helm-charts
   helm repo update
   helm upgrade --install grafana-k8s-monitoring grafana/k8s-monitoring \
     --namespace "monitoring" --values my-grafana-values.yaml
   ```
3. **Dashboarding**: Real-time visualization of Pod CPU, Memory spikes, and LLM API latency.

---

## ğŸ“Š Performance Benchmarks

| Metric | Target | Real-World Performance (Groq) |
| :--- | :--- | :--- |
| **Vector Search Latency** | < 20ms | ~12ms |
| **LLM Inference (TPS)** | > 200 | ~240 (LPU Optimized) |
| **UI Load Time** | < 2s | ~1.4s |
| **Scale Capability** | 10k Records | Tested at 14k+ entries |

---

## ğŸ› ï¸ Developer Setup

### ğŸ“¦ Prerequisites
- **Python 3.11+**
- **Git LFS** (Handles large `.bin` and `.sqlite3` files up to 2GB)
- **Groq API Key** (Get it at [Groq Console](https://console.groq.com/))

### ğŸš€ Quick Start
```bash
# Clone & Initialize LFS
git clone https://github.com/Ratnesh-181998/Agentic-RAG-Anime-Recommender-System.git
git lfs install
git lfs pull

# Environment Setup
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Run Local Server
streamlit run Code/app/premium_dashboard.py
```

### ï¿½ï¸ Environment Variables
| Variable | Description | Source |
| :--- | :--- | :--- |
| `GROQ_API_KEY` | Core LLM Inference Key | [Groq Cloud](https://console.groq.com/keys) |

---

## ğŸ›¤ï¸ Future Roadmap

- [ ] **Multimodal Search**: Search using images/frames from anime.
- [ ] **Streaming Responses**: Real-time token streaming in the UI.
- [ ] **Collaborative Filtering**: Integration of Hybrid-RAG (User-ratings + Semantic).
- [ ] **Grafana Integration**: Export logs to a dedicated monitoring dashboard.

---

## ğŸ“ Contact & Networking

**Ratnesh Kumar Singh | Data Scientist (AI/ML Engineer)**
*4+ Years of Professional Experience in Building Production AI Systems*

- ğŸ’¼ **LinkedIn**: [Connect with me](https://www.linkedin.com/in/ratneshkumar1998/)
- ğŸ™ **GitHub**: [Review my Repos](https://github.com/Ratnesh-181998)
- ğŸŒ **Live Project**: [Explore the App](https://appudtzei3tyyttd6xjhwur.streamlit.app/)

---

## ğŸ“œ License
Licensed under the **MIT License**. Feel free to fork and build upon this innovation.

---
*Built with passion for the AI Community. ğŸš€*
